{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/neaf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/neaf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/neaf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/neaf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/neaf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/neaf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/neaf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/neaf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/neaf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/neaf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/neaf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertConfig,AdamW, BertForSequenceClassification,get_linear_schedule_with_warmup\n",
    "import sys\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "# Import and evaluate each test batch using Matthew's correlation coefficient\n",
    "from sklearn.metrics import accuracy_score,matthews_corrcoef\n",
    "\n",
    "from tqdm import tqdm, trange,tnrange,tqdm_notebook\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "\n",
    "train_identification = pd.read_csv('dm2020-hw2-nthu/data_identification.csv')\n",
    "train_emotion = pd.read_csv('dm2020-hw2-nthu/emotion.csv')\n",
    "sample_submit = pd.read_csv('dm2020-hw2-nthu/sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_feature = pd.read_json('dm2020-hw2-nthu/tweets_DM.json', lines=True)\n",
    "data = pd.merge(train_identification, train_emotion, on=[\"tweet_id\"])\n",
    "\n",
    "identification_train = data['identification'] == 'train'\n",
    "identification_test = train_identification['identification'] == 'test'\n",
    "\n",
    "train_X = data.loc[identification_train]\n",
    "test_X = train_identification.loc[identification_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "test_X['emotion'] = np.nan\n",
    "df = pd.concat([train_X, test_X])\n",
    "\n",
    "json_feature['hashtags'] = np.nan; json_feature['text'] = np.nan\n",
    "json_extend = pd.io.json.json_normalize(json_feature._source)\n",
    "json_extend['tweet.text'].isna().sum()\n",
    "json_feature['hashtags'] = json_extend['tweet.hashtags']\n",
    "json_feature['text'] = json_extend['tweet.text']\n",
    "json_feature['tweet_id'] = json_extend['tweet.tweet_id']\n",
    "\n",
    "df = pd.merge(df, json_feature, on=[\"tweet_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'trust', 'anticipation', 'sadness', 'disgust', 'fear',\n",
       "       'surprise', 'anger'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.loc[df['identification'] == 'train']\n",
    "df_test = df.loc[df['identification'] == 'test']\n",
    "\n",
    "df_train['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df_train['emotion_enc'] = labelencoder.fit_transform(df_train['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>_score</th>\n",
       "      <th>_index</th>\n",
       "      <th>_source</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>_type</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>809</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x29e4...</td>\n",
       "      <td>2015-01-17 03:07:03</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[]</td>\n",
       "      <td>Huge Respectüñí @JohnnyVegasReal talking about l...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>808</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['spateradio', 'app'], ...</td>\n",
       "      <td>2016-07-02 09:34:06</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[spateradio, app]</td>\n",
       "      <td>Yoooo we hit all our monthly goals with the ne...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "      <td>trust</td>\n",
       "      <td>16</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2a2a...</td>\n",
       "      <td>2016-08-15 18:18:39</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[]</td>\n",
       "      <td>@KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2a8830</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>768</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['PUBG', 'GamersUnite',...</td>\n",
       "      <td>2017-02-11 08:49:46</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[PUBG, GamersUnite, twitch, BeHealthy, StayPos...</td>\n",
       "      <td>Come join @ambushman27 on #PUBG while he striv...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x20b21d</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>70</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['strength', 'bones', '...</td>\n",
       "      <td>2016-11-23 05:37:10</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[strength, bones, God]</td>\n",
       "      <td>@fanshixieen2014 Blessings!My #strength little...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id identification       emotion  _score          _index  \\\n",
       "0  0x29e452          train           joy     809  hashtag_tweets   \n",
       "1  0x2b3819          train           joy     808  hashtag_tweets   \n",
       "2  0x2a2acc          train         trust      16  hashtag_tweets   \n",
       "3  0x2a8830          train           joy     768  hashtag_tweets   \n",
       "4  0x20b21d          train  anticipation      70  hashtag_tweets   \n",
       "\n",
       "                                             _source           _crawldate  \\\n",
       "0  {'tweet': {'hashtags': [], 'tweet_id': '0x29e4...  2015-01-17 03:07:03   \n",
       "1  {'tweet': {'hashtags': ['spateradio', 'app'], ...  2016-07-02 09:34:06   \n",
       "2  {'tweet': {'hashtags': [], 'tweet_id': '0x2a2a...  2016-08-15 18:18:39   \n",
       "3  {'tweet': {'hashtags': ['PUBG', 'GamersUnite',...  2017-02-11 08:49:46   \n",
       "4  {'tweet': {'hashtags': ['strength', 'bones', '...  2016-11-23 05:37:10   \n",
       "\n",
       "    _type                                           hashtags  \\\n",
       "0  tweets                                                 []   \n",
       "1  tweets                                  [spateradio, app]   \n",
       "2  tweets                                                 []   \n",
       "3  tweets  [PUBG, GamersUnite, twitch, BeHealthy, StayPos...   \n",
       "4  tweets                             [strength, bones, God]   \n",
       "\n",
       "                                                text  emotion_enc  \n",
       "0  Huge Respectüñí @JohnnyVegasReal talking about l...            4  \n",
       "1  Yoooo we hit all our monthly goals with the ne...            4  \n",
       "2  @KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...            7  \n",
       "3  Come join @ambushman27 on #PUBG while he striv...            4  \n",
       "4  @fanshixieen2014 Blessings!My #strength little...            1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,1), tokenizer = token.tokenize)\n",
    "text = cv.fit_transform(df_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text,df_train['emotion_enc'], test_size=0.30, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = mnb.predict(X_test)\n",
    "pred = mnb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train_score: 61.47%\n",
      "acc_train_score: 52.84%\n",
      "Precision: 65.70%\n",
      "Recall: 34.88%\n",
      "F1 Score:  0.38508794871220503\n",
      "[[  1164    706   1466     26   5617   2626      6    290]\n",
      " [    13  38692   1278    124  28873   3203     27   2533]\n",
      " [    16   1756  13748     80  14947  10031     26    961]\n",
      " [     6   1482    698   3451  11142   1844      7    523]\n",
      " [    25  10951   2330    403 129363   5417    118   6225]\n",
      " [    20   2636   4483    104  22418  27339     38   1252]\n",
      " [     3    893   1181     35   7831   2754   1606    468]\n",
      " [    11   6631   1420    104  35001   2822     44  15381]]\n"
     ]
    }
   ],
   "source": [
    "acc_test_score = metrics.accuracy_score(predicted,y_test)\n",
    "acc_train_score = metrics.accuracy_score(pred,y_train)\n",
    "\n",
    "prec_score = precision_score(y_test,predicted, average='macro')\n",
    "recall = recall_score(y_test, predicted,average='macro')\n",
    "f1 = f1_score(y_test,predicted,average='macro')\n",
    "matrix = confusion_matrix(y_test,predicted)\n",
    "\n",
    "print(str('acc_train_score: '+'{:04.2f}'.format(acc_train_score*100))+'%')\n",
    "print(str('acc_train_score: '+'{:04.2f}'.format(acc_test_score*100))+'%')\n",
    "\n",
    "print(str('Precision: '+'{:04.2f}'.format(prec_score*100))+'%')\n",
    "print(str('Recall: '+'{:04.2f}'.format(recall*100))+'%')\n",
    "print('F1 Score: ',f1)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text = cv.transform(df_test['text'])\n",
    "submit_pred = mnb.predict(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = labelencoder.inverse_transform(submit_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test['emotion'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>_score</th>\n",
       "      <th>_index</th>\n",
       "      <th>_source</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>_type</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>emption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1455563</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x28cc...</td>\n",
       "      <td>2017-01-17 14:13:32</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[]</td>\n",
       "      <td>@Habbo I've seen two separate colours of the e...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455564</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>728</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2db4...</td>\n",
       "      <td>2015-10-17 06:46:20</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[]</td>\n",
       "      <td>@FoxNews @KellyannePolls No serious self respe...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455565</th>\n",
       "      <td>0x2466f6</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>491</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['womendrivers'], 'twee...</td>\n",
       "      <td>2016-12-19 03:50:27</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[womendrivers]</td>\n",
       "      <td>Looking for a new car, and it says 1 lady owne...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455566</th>\n",
       "      <td>0x23f9e9</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['robbingmembers'], 'tw...</td>\n",
       "      <td>2017-04-09 19:32:19</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[robbingmembers]</td>\n",
       "      <td>@cineworld ‚Äúonly the brave‚Äù just out and fount...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455567</th>\n",
       "      <td>0x1fb4e1</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>925</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1fb4...</td>\n",
       "      <td>2016-01-15 11:59:31</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[]</td>\n",
       "      <td>Felt like total dog üí© going into open gym and ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification emotion  _score          _index  \\\n",
       "1455563  0x28cc61           test     NaN     107  hashtag_tweets   \n",
       "1455564  0x2db41f           test     NaN     728  hashtag_tweets   \n",
       "1455565  0x2466f6           test     NaN     491  hashtag_tweets   \n",
       "1455566  0x23f9e9           test     NaN      28  hashtag_tweets   \n",
       "1455567  0x1fb4e1           test     NaN     925  hashtag_tweets   \n",
       "\n",
       "                                                   _source  \\\n",
       "1455563  {'tweet': {'hashtags': [], 'tweet_id': '0x28cc...   \n",
       "1455564  {'tweet': {'hashtags': [], 'tweet_id': '0x2db4...   \n",
       "1455565  {'tweet': {'hashtags': ['womendrivers'], 'twee...   \n",
       "1455566  {'tweet': {'hashtags': ['robbingmembers'], 'tw...   \n",
       "1455567  {'tweet': {'hashtags': [], 'tweet_id': '0x1fb4...   \n",
       "\n",
       "                  _crawldate   _type          hashtags  \\\n",
       "1455563  2017-01-17 14:13:32  tweets                []   \n",
       "1455564  2015-10-17 06:46:20  tweets                []   \n",
       "1455565  2016-12-19 03:50:27  tweets    [womendrivers]   \n",
       "1455566  2017-04-09 19:32:19  tweets  [robbingmembers]   \n",
       "1455567  2016-01-15 11:59:31  tweets                []   \n",
       "\n",
       "                                                      text  emption  \n",
       "1455563  @Habbo I've seen two separate colours of the e...      joy  \n",
       "1455564  @FoxNews @KellyannePolls No serious self respe...  sadness  \n",
       "1455565  Looking for a new car, and it says 1 lady owne...      joy  \n",
       "1455566  @cineworld ‚Äúonly the brave‚Äù just out and fount...      joy  \n",
       "1455567  Felt like total dog üí© going into open gym and ...      joy  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['tweet_id', 'emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
