{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "# Import and evaluate each test batch using Matthew's correlation coefficient\n",
    "from sklearn.metrics import accuracy_score,matthews_corrcoef\n",
    "\n",
    "from tqdm import tqdm, trange,tnrange,tqdm_notebook\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "\n",
    "train_identification = pd.read_csv('dm2020-hw2-nthu/data_identification.csv')\n",
    "train_emotion = pd.read_csv('dm2020-hw2-nthu/emotion.csv')\n",
    "sample_submit = pd.read_csv('dm2020-hw2-nthu/sampleSubmission.csv')\n",
    "json_feature = pd.read_json('dm2020-hw2-nthu/tweets_DM.json', lines=True)\n",
    "data = pd.merge(train_identification, train_emotion, on=[\"tweet_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "identification_train = data['identification'] == 'train'\n",
    "identification_test = train_identification['identification'] == 'test'\n",
    "\n",
    "train_X = data.loc[identification_train]\n",
    "test_X = train_identification.loc[identification_test]\n",
    "\n",
    "test_X['emotion'] = np.nan\n",
    "df = pd.concat([train_X, test_X])\n",
    "\n",
    "json_feature['hashtags'] = np.nan; json_feature['text'] = np.nan\n",
    "json_extend = pd.io.json.json_normalize(json_feature._source)\n",
    "json_extend['tweet.text'].isna().sum()\n",
    "json_feature['hashtags'] = json_extend['tweet.hashtags']\n",
    "json_feature['text'] = json_extend['tweet.text']\n",
    "json_feature['tweet_id'] = json_extend['tweet.tweet_id']\n",
    "\n",
    "df = pd.merge(df, json_feature, on=[\"tweet_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'trust', 'anticipation', 'sadness', 'disgust', 'fear',\n",
       "       'surprise', 'anger'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.loc[df['identification'] == 'train']\n",
    "df_test = df.loc[df['identification'] == 'test']\n",
    "\n",
    "df_train['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df_train['emotion_enc'] = labelencoder.fit_transform(df_train['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(min_df=150, \n",
    "                     max_features=5000, \n",
    "                     strip_accents='unicode',\n",
    "                     analyzer='word',\n",
    "                     token_pattern=r'\\w{1,}',\n",
    "                     stop_words='english', \n",
    "                     ngram_range=(1,2),\n",
    "                     tokenizer = token.tokenize,\n",
    ")\n",
    "\n",
    "cv2 = CountVectorizer(#sublinear_tf=True,\n",
    "                      strip_accents='unicode',\n",
    "                      analyzer='char',\n",
    "                      stop_words='english',\n",
    "                      ngram_range=(2,6),\n",
    "                      max_features=10000,\n",
    "    tokenizer = token.tokenize,\n",
    ")\n",
    "\n",
    "word = cv.fit_transform(df_train['text'])\n",
    "char = cv2.fit_transform(df_train['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "text= hstack([word, char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455563, 15000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text,\n",
    "                                                    df_train['emotion'], \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "mnb = RidgeClassifierCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(X_train, y_train)\n",
    "predicted = mnb.predict(X_test)\n",
    "pred = mnb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "acc_test_score = metrics.accuracy_score(predicted,y_test)\n",
    "acc_train_score = metrics.accuracy_score(pred,y_train)\n",
    "\n",
    "prec_score = precision_score(y_test,predicted, average='macro')\n",
    "recall = recall_score(y_test, predicted,average='macro')\n",
    "f1 = f1_score(y_test,predicted,average='macro')\n",
    "matrix = confusion_matrix(y_test,predicted)\n",
    "\n",
    "print(str('acc_train_score: '+'{:04.2f}'.format(acc_train_score*100))+'%')\n",
    "print(str('acc_train_score: '+'{:04.2f}'.format(acc_test_score*100))+'%')\n",
    "\n",
    "print(str('Precision: '+'{:04.2f}'.format(prec_score*100))+'%')\n",
    "print(str('Recall: '+'{:04.2f}'.format(recall*100))+'%')\n",
    "print('F1 Score: ',f1)\n",
    "print(matrix)\n",
    "'''\n",
    "bayesian can't \n",
    "SGD no parameters -> 55\n",
    "can add max_iter to 2000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "mnb.fit(text, df_train['emotion'])\n",
    "\n",
    "pred_word = cv.transform(df_test['text'])\n",
    "pred_char = cv2.transform(df_test['text'])\n",
    "pred_text = hstack([pred_word, pred_char])\n",
    "\n",
    "submit_pred = mnb.predict(pred_text)\n",
    "result = labelencoder.inverse_transform(submit_pred)\n",
    "\n",
    "df_test['id'] = df_test['tweet_id']\n",
    "df_test['emotion'] = result\n",
    "\n",
    "df_test[['id', 'emotion']].to_csv('submission/TFIDF_MultinomialNB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/neaf/.kaggle/kaggle.json'\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/neaf/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.30M/6.30M [00:07<00:00, 856kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to DM20 HW2 Kaggle Competition"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "api.competition_submit('submission/TFIDF_MultinomialNB.csv', 'API Submission', 'dm2020-hw2-nthu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
