{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "# Import and evaluate each test batch using Matthew's correlation coefficient\n",
    "from sklearn.metrics import accuracy_score,matthews_corrcoef\n",
    "\n",
    "from tqdm import tqdm, trange,tnrange,tqdm_notebook\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "\n",
    "train_identification = pd.read_csv('dm2020-hw2-nthu/data_identification.csv')\n",
    "train_emotion = pd.read_csv('dm2020-hw2-nthu/emotion.csv')\n",
    "sample_submit = pd.read_csv('dm2020-hw2-nthu/sampleSubmission.csv')\n",
    "json_feature = pd.read_json('dm2020-hw2-nthu/tweets_DM.json', lines=True)\n",
    "data = pd.merge(train_identification, train_emotion, on=[\"tweet_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "identification_train = data['identification'] == 'train'\n",
    "identification_test = train_identification['identification'] == 'test'\n",
    "\n",
    "train_X = data.loc[identification_train]\n",
    "test_X = train_identification.loc[identification_test]\n",
    "\n",
    "test_X['emotion'] = np.nan\n",
    "df = pd.concat([train_X, test_X])\n",
    "\n",
    "json_feature['hashtags'] = np.nan; json_feature['text'] = np.nan\n",
    "json_extend = pd.io.json.json_normalize(json_feature._source)\n",
    "json_extend['tweet.text'].isna().sum()\n",
    "json_feature['hashtags'] = json_extend['tweet.hashtags']\n",
    "json_feature['text'] = json_extend['tweet.text']\n",
    "json_feature['tweet_id'] = json_extend['tweet.tweet_id']\n",
    "\n",
    "df = pd.merge(df, json_feature, on=[\"tweet_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'trust', 'anticipation', 'sadness', 'disgust', 'fear',\n",
       "       'surprise', 'anger'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.loc[df['identification'] == 'train']\n",
    "df_test = df.loc[df['identification'] == 'test']\n",
    "\n",
    "df_train['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df_train['emotion_enc'] = labelencoder.fit_transform(df_train['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = TfidfVectorizer(#min_df=150, \n",
    "                     max_features=5000000, \n",
    "                     strip_accents='unicode',\n",
    "                     analyzer='word',\n",
    "                     token_pattern=r'\\w{1,}',\n",
    "                     stop_words='english', \n",
    "                     ngram_range=(1,2),\n",
    ")\n",
    "\n",
    "cv2 = TfidfVectorizer(sublinear_tf=True,\n",
    "                      strip_accents='unicode',\n",
    "                      analyzer='char',\n",
    "                      stop_words='english',\n",
    "                      ngram_range=(2,6),\n",
    "                      max_features=5000000,\n",
    ")\n",
    "\n",
    "word = cv.fit_transform(df_train['text'])\n",
    "char = cv2.fit_transform(df_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "text= hstack([word, char])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text,\n",
    "                                                    df_train['emotion'], \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifierCV\n",
    "\n",
    "mnb = LogisticRegression(solver='sag')\n",
    "mnb_tuning = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_tuning.fit(X_train, y_train)\n",
    "predicted = mnb_tuning.predict(X_test)\n",
    "pred = mnb_tuning.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train_score: 58.66%\n",
      "acc_train_score: 54.61%\n",
      "Precision: 74.01%\n",
      "Recall: 34.77%\n",
      "F1 Score:  0.38838487803609223\n",
      "[[  1058    493   1040     10   6574   2594      2    130]\n",
      " [     1  38700    733     27  31050   2938      8   1286]\n",
      " [     3   1099  11659     38  18065  10279      6    416]\n",
      " [     0   1214    547   3563  11676   1928      0    225]\n",
      " [     2   6991   1146     64 140032   3639     12   2946]\n",
      " [     1   1571   2933     50  25114  28108      9    504]\n",
      " [     0    540    816     14   9081   2730   1401    189]\n",
      " [     0   5157    740     12  39452   2091      6  13956]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nacc_train_score: 57.52%\\nacc_train_score: 57.53%\\nPrecision: 60.35%\\nRecall: 43.45%\\nupdate max\\nacc_train_score: 59.12%\\nacc_train_score: 57.86%\\nPrecision: 58.85%\\nRecall: 44.77%\\n\\n----iterator 10000----\\nacc_train_score: 56.07%\\nacc_train_score: 55.09%\\nPrecision: 53.01%\\nRecall: 40.25%\\n\\nlogist -> 25000\\nslove=sag\\nacc_train_score: 62.72%\\nacc_train_score: 59.40%\\n\\n-> 30000\\nacc_train_score: 63.07%\\nacc_train_score: 59.54%\\n\\n- 100000\\nbay\\nacc_train_score: 56.45%\\nacc_train_score: 53.93%\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "acc_test_score = metrics.accuracy_score(predicted,y_test)\n",
    "acc_train_score = metrics.accuracy_score(pred,y_train)\n",
    "\n",
    "prec_score = precision_score(y_test,predicted, average='macro')\n",
    "recall = recall_score(y_test, predicted,average='macro')\n",
    "f1 = f1_score(y_test,predicted,average='macro')\n",
    "matrix = confusion_matrix(y_test,predicted)\n",
    "\n",
    "print(str('acc_train_score: '+'{:04.2f}'.format(acc_train_score*100))+'%')\n",
    "print(str('acc_train_score: '+'{:04.2f}'.format(acc_test_score*100))+'%')\n",
    "\n",
    "print(str('Precision: '+'{:04.2f}'.format(prec_score*100))+'%')\n",
    "print(str('Recall: '+'{:04.2f}'.format(recall*100))+'%')\n",
    "print('F1 Score: ',f1)\n",
    "print(matrix)\n",
    "'''\n",
    "acc_train_score: 57.52%\n",
    "acc_train_score: 57.53%\n",
    "Precision: 60.35%\n",
    "Recall: 43.45%\n",
    "update max\n",
    "acc_train_score: 59.12%\n",
    "acc_train_score: 57.86%\n",
    "Precision: 58.85%\n",
    "Recall: 44.77%\n",
    "\n",
    "----iterator 10000----\n",
    "acc_train_score: 56.07%\n",
    "acc_train_score: 55.09%\n",
    "Precision: 53.01%\n",
    "Recall: 40.25%\n",
    "\n",
    "logist -> 25000\n",
    "slove=sag\n",
    "acc_train_score: 62.72%\n",
    "acc_train_score: 59.40%\n",
    "\n",
    "-> 30000\n",
    "acc_train_score: 63.07%\n",
    "acc_train_score: 59.54%\n",
    "\n",
    "- 100000\n",
    "bay\n",
    "acc_train_score: 56.45%\n",
    "acc_train_score: 53.93%\n",
    "- 1000000\n",
    "acc_train_score: 58.66%\n",
    "acc_train_score: 54.61%\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/neaf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "mnb.fit(text, df_train['emotion'])\n",
    "\n",
    "pred_word = cv.transform(df_test['text'])\n",
    "pred_char = cv2.transform(df_test['text'])\n",
    "pred_text = hstack([pred_word, pred_char])\n",
    "\n",
    "submit_pred = mnb.predict(pred_text)\n",
    "#result = labelencoder.inverse_transform(submit_pred)\n",
    "\n",
    "df_test['id'] = df_test['tweet_id']\n",
    "df_test['emotion'] = submit_pred\n",
    "\n",
    "df_test[['id', 'emotion']].to_csv('submission/TFIDF_logistic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/neaf/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.13M/6.13M [00:05<00:00, 1.11MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to DM20 HW2 Kaggle Competition"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "api.competition_submit('submission/TFIDF_logistic.csv', 'API Submission', 'dm2020-hw2-nthu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
